---
id: "1236"
title: "Web Crawler"
companyTags: "Unknown"
slug: "web-crawler"
difficulty: "Medium"
tags: ["String", "Depth-First Search", "Breadth-First Search", "Interactive"]
---

## Explanation:

To implement a web crawler, we can use a breadth-first search (BFS) algorithm to traverse the web pages starting from the given URL. We keep track of visited URLs to avoid revisiting the same URL and also maintain a queue of URLs to visit next. We continue this process until the queue is empty.

**Algorithm:**
1. Initialize a set to store visited URLs and a queue to store URLs to visit.
2. Add the start URL to the queue and mark it as visited.
3. While the queue is not empty, do the following:
   - Dequeue a URL from the queue.
   - Retrieve the HTML content of the URL.
   - Extract all the links from the HTML content.
   - For each extracted link, if it has not been visited before, add it to the queue and mark it as visited.
4. Continue this process until the queue is empty.

**Time Complexity:**
The time complexity of the BFS traversal in the worst-case scenario is O(V + E), where V is the number of vertices (URLs) and E is the number of edges (links between URLs) in the web graph.

**Space Complexity:**
The space complexity is O(V) to store the visited URLs and the queue.

:
:
```java
class Solution {
    public List<String> crawl(String startUrl, HtmlParser htmlParser) {
        Set<String> visited = new HashSet<>();
        Queue<String> queue = new LinkedList<>();
        String hostname = getHostname(startUrl);
        
        List<String> result = new ArrayList<>();
        queue.offer(startUrl);
        visited.add(startUrl);
        
        while (!queue.isEmpty()) {
            String currUrl = queue.poll();
            result.add(currUrl);
            
            List<String> links = htmlParser.getUrls(currUrl);
            for (String link : links) {
                if (isSameHostname(link, hostname) && !visited.contains(link)) {
                    queue.offer(link);
                    visited.add(link);
                }
            }
        }
        
        return result;
    }
    
    private String getHostname(String url) {
        // Implement logic to extract hostname from URL
    }
    
    private boolean isSameHostname(String url, String hostname) {
        // Implement logic to check if URL has the same hostname
    }
}
```

### C++:
```cpp
class Solution {
public:
    vector<string> crawl(string startUrl, HtmlParser htmlParser) {
        unordered_set<string> visited;
        queue<string> q;
        string hostname = getHostname(startUrl);
        
        vector<string> result;
        q.push(startUrl);
        visited.insert(startUrl);
        
        while (!q.empty()) {
            string currUrl = q.front();
            q.pop();
            result.push_back(currUrl);
            
            vector<string> links = htmlParser.getUrls(currUrl);
            for (string link : links) {
                if (isSameHostname(link, hostname) && visited.find(link) == visited.end()) {
                    q.push(link);
                    visited.insert(link);
                }
            }
        }
        
        return result;
    }
    
    string getHostname(string url) {
        // Implement logic to extract hostname from URL
    }
    
    bool isSameHostname(string url, string hostname) {
        // Implement logic to check if URL has the same hostname
    }
};
```

### Python:
```python
class Solution:
    def crawl(self, startUrl: str, htmlParser: 'HtmlParser') -> List[str]:
        visited = set()
        queue = deque()
        hostname = self.getHostname(startUrl)
        
        result = []
        queue.append(startUrl)
        visited.add(startUrl)
        
        while queue:
            currUrl = queue.popleft()
            result.append(currUrl)
            
            links = htmlParser.getUrls(currUrl)
            for link in links:
                if self.isSameHostname(link, hostname) and link not in visited:
                    queue.append(link)
                    visited.add(link)
        
        return result
    
    def getHostname(self, url: str) -> str:
        # Implement logic to extract hostname from URL
    
    def isSameHostname(self, url: str, hostname: str) -> bool:
        # Implement logic to check if URL has the same hostname
```