---
id: "3225"
title: "Maximum Score From Grid Operations"
companyTags: "Unknown"
slug: "maximum-score-from-grid-operations"
difficulty: "Hard"
tags: ["Array", "Dynamic Programming", "Matrix", "Prefix Sum"]
---

## Explanation:
To maximize the score, we need to find the optimal sequence of operations that will result in the highest score. We can achieve this by considering all possible operations and calculating the score after each operation.

1. Initialize an empty list `rows` and list `cols` with n zeros.
2. Iterate through all cells and update the `rows` and `cols` lists with the row and column sums of the grid.
3. For each operation, we consider coloring a column from top to bottom. We calculate the score that can be obtained by coloring a specific column.
4. To calculate the score after an operation, we iterate through all cells and check if coloring a specific column would increase the score. If so, we update the score.
5. Repeat the above step for all possible operations and return the maximum score obtained.

### Time Complexity:
The time complexity is O(n^3) where n is the size of the grid since we are iterating through the grid and considering all possible operations.

### Space Complexity:
The space complexity is O(n) for storing the row and column sums.

:

```java
class Solution {
    public int maxGridScore(int[][] grid) {
        int n = grid.length;
        int[] rows = new int[n];
        int[] cols = new int[n];
        
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                rows[i] += grid[i][j];
                cols[j] += grid[i][j];
            }
        }
        
        int maxScore = 0;
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                int score = rows[i] + cols[j] - grid[i][j];
                maxScore = Math.max(maxScore, score);
            }
        }
        
        return maxScore;
    }
}
```

### C++
```cpp
class Solution {
public:
    int maxGridScore(vector<vector<int>>& grid) {
        int n = grid.size();
        vector<int> rows(n, 0);
        vector<int> cols(n, 0);
        
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                rows[i] += grid[i][j];
                cols[j] += grid[i][j];
            }
        }
        
        int maxScore = 0;
        for (int i = 0; i < n; i++) {
            for (int j = 0; j < n; j++) {
                int score = rows[i] + cols[j] - grid[i][j];
                maxScore = max(maxScore, score);
            }
        }
        
        return maxScore;
    }
};
```

### Python
```python
class Solution:
    def maxGridScore(self, grid: List[List[int]]) -> int:
        n = len(grid)
        rows = [0] * n
        cols = [0] * n
        
        for i in range(n):
            for j in range(n):
                rows[i] += grid[i][j]
                cols[j] += grid[i][j]
        
        maxScore = 0
        for i in range(n):
            for j in range(n):
                score = rows[i] + cols[j] - grid[i][j]
                maxScore = max(maxScore, score)
        
        return maxScore
```