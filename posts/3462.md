---
id: "3462"
title: "Maximum Sum With at Most K Elements"
companyTags: "Unknown"
slug: "maximum-sum-with-at-most-k-elements"
difficulty: "Medium"
tags: ["Array", "Greedy", "Sorting", "Heap (Priority Queue)", "Matrix"]
---

### Explanation:
To solve this problem, we can use a dynamic programming approach. We will iterate over each row of the matrix grid and for each row, we will maintain a 1D array dp where dp[j] represents the maximum sum of at most j elements taken from that row. We will update dp array for each row based on the elements that can be selected without exceeding the limits.

1. Initialize a 2D dp array of size n x (k + 1) where dp[i][j] represents the maximum sum of at most j elements taken from the first i rows.
2. Iterate over each row of the matrix grid.
3. For each row i, update the dp array based on the elements that can be selected without exceeding the limits[i].
4. Finally, return the maximum sum from the last row of the dp array.
 Solution:
```java
class Solution {
    public int maxMatrixSum(int[][] grid, int[] limits, int k) {
        int n = grid.length;
        int m = grid[0].length;
        int[][] dp = new int[n][k + 1];

        for (int i = 0; i < n; i++) {
            int[] tmp = new int[k + 1];
            for (int j = 0; j <= k; j++) {
                dp[i][j] = Integer.MIN_VALUE;
            }

            for (int j = 0; j < m; j++) {
                for (int l = k; l >= 0; l--) {
                    int limit = limits[i];
                    if (l < limit) {
                        dp[i][l + 1] = Math.max(dp[i][l + 1], dp[i][l] + grid[i][j]);
                    }
                    tmp[l] = Math.max(tmp[l], dp[i][l]);
                }
            }
            for (int j = 0; j <= k; j++) {
                dp[i][j] = tmp[j];
            }
        }

        return dp[n - 1][k];
    }
}
```

### C++ Solution:
```cpp
class Solution {
public:
    int maxMatrixSum(vector<vector<int>>& grid, vector<int>& limits, int k) {
        int n = grid.size();
        int m = grid[0].size();
        vector<vector<int>> dp(n, vector<int>(k + 1));

        for (int i = 0; i < n; i++) {
            vector<int> tmp(k + 1, 0);

            for (int j = 0; j <= k; j++) {
                dp[i][j] = INT_MIN;
            }

            for (int j = 0; j < m; j++) {
                for (int l = k; l >= 0; l--) {
                    int limit = limits[i];
                    if (l < limit) {
                        dp[i][l + 1] = max(dp[i][l + 1], dp[i][l] + grid[i][j]);
                    }
                    tmp[l] = max(tmp[l], dp[i][l]);
                }
            }

            for (int j = 0; j <= k; j++) {
                dp[i][j] = tmp[j];
            }
        }

        return dp[n - 1][k];
    }
};
```

### Python Solution:
```python
class Solution:
    def maxMatrixSum(self, grid: List[List[int]], limits: List[int], k: int) -> int:
        n = len(grid)
        m = len(grid[0])
        dp = [[0] * (k + 1) for _ in range(n)]

        for i in range(n):
            tmp = [0] * (k + 1)

            for j in range(k + 1):
                dp[i][j] = float('-inf')

            for j in range(m):
                for l in range(k, -1, -1):
                    limit = limits[i]
                    if l < limit:
                        dp[i][l + 1] = max(dp[i][l + 1], dp[i][l] + grid[i][j])
                    tmp[l] = max(tmp[l], dp[i][l])

            for j in range(k + 1):
                dp[i][j] = tmp[j]

        return dp[n - 1][k]
```