---
id: "3500"
title: "Minimum Cost to Divide Array Into Subarrays"
companyTags: "Unknown"
slug: "minimum-cost-to-divide-array-into-subarrays"
difficulty: "Hard"
tags: ["Array", "Dynamic Programming", "Prefix Sum"]
---

### Explanation:
To solve this problem, we can use dynamic programming. We can define a dp array where dp[i] represents the minimum cost to divide the subarray nums[0...i] into subarrays according to the given constraints. We can iterate over all possible indices to divide the array and calculate the cost at each division point. The final answer will be dp[n-1], where n is the size of the input arrays.

Here are the steps:
1. Initialize a dp array of size n where n is the size of the input arrays.
2. Iterate over all possible indices to divide the array and calculate the cost at each division point.
3. Update dp[i] with the minimum cost obtained from all possible divisions before index i.
4. Return dp[n-1] as the final answer.

**Time Complexity:** O(n^2) where n is the size of the input arrays.

**Space Complexity:** O(n) where n is the size of the input arrays.

```java
class Solution {
    public int minCost(int[] nums, int[] cost, int k) {
        int n = nums.length;
        int[] dp = new int[n];
        
        for (int i = 1; i < n; i++) {
            dp[i] = Integer.MAX_VALUE;
            int sum = nums[i];
            int totalCost = cost[i];
            
            for (int j = i; j >= 0 && j >= i - k + 1; j--) {
                dp[i] = Math.min(dp[i], dp[j - 1] + (sum + k * (i - j + 1)) * totalCost);
                
                if (j > 0) {
                    sum += nums[j - 1];
                    totalCost += cost[j - 1];
                }
            }
        }
        
        return dp[n - 1];
    }
}
```

#### C++
```cpp
class Solution {
public:
    int minCost(vector<int>& nums, vector<int>& cost, int k) {
        int n = nums.size();
        vector<int> dp(n, 0);
        
        for (int i = 1; i < n; i++) {
            dp[i] = INT_MAX;
            int sum = nums[i];
            int totalCost = cost[i];
            
            for (int j = i; j >= 0 && j >= i - k + 1; j--) {
                dp[i] = min(dp[i], dp[j - 1] + (sum + k * (i - j + 1)) * totalCost);
                
                if (j > 0) {
                    sum += nums[j - 1];
                    totalCost += cost[j - 1];
                }
            }
        }
        
        return dp[n - 1];
    }
};
```

#### Python
```python
class Solution:
    def minCost(self, nums: List[int], cost: List[int], k: int) -> int:
        n = len(nums)
        dp = [0] * n
        
        for i in range(1, n):
            dp[i] = float('inf')
            total_sum = nums[i]
            total_cost = cost[i]
            
            for j in range(i, max(0, i - k), -1):
                dp[i] = min(dp[i], dp[j - 1] + (total_sum + k * (i - j + 1)) * total_cost)
                
                if j > 0:
                    total_sum += nums[j - 1]
                    total_cost += cost[j - 1]
        
        return dp[-1]
```