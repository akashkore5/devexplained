---
id: "609"
title: "Find Duplicate File in System"
companyTags: "Unknown"
slug: "find-duplicate-file-in-system"
difficulty: "Medium"
tags: ["Array", "Hash Table", "String"]
---

### Explanation:
To solve this problem, we can use a hashmap where the key is the file content and the value is a list of file paths with that content. We iterate through each directory info string, extract the file content and file paths, and store them in the hashmap. Finally, we collect all the values from the hashmap where the list size is greater than 1, as these are the duplicate files.

- **Time Complexity**: O(n * k) where n is the number of directory info strings and k is the average length of a directory info string.
- **Space Complexity**: O(n * k) for the hashmap.

:

```java
import java.util.*;

class Solution {
    public List<List<String>> findDuplicate(String[] paths) {
        Map<String, List<String>> map = new HashMap<>();
        
        for (String path : paths) {
            String[] parts = path.split(" ");
            String directory = parts[0];
            
            for (int i = 1; i < parts.length; i++) {
                String[] fileInfo = parts[i].split("\\(");
                String fileName = fileInfo[0];
                String content = fileInfo[1].substring(0, fileInfo[1].length() - 1);
                String fullPath = directory + "/" + fileName;
                
                map.putIfAbsent(content, new ArrayList<>());
                map.get(content).add(fullPath);
            }
        }
        
        List<List<String>> result = new ArrayList<>();
        for (List<String> files : map.values()) {
            if (files.size() > 1) {
                result.add(files);
            }
        }
        
        return result;
    }
}
```

```cpp
class Solution {
public:
    vector<vector<string>> findDuplicate(vector<string>& paths) {
        unordered_map<string, vector<string>> contentToFiles;
        
        for (string path : paths) {
            istringstream iss(path);
            string directory, fileInfo;
            iss >> directory;
            
            while (iss >> fileInfo) {
                size_t openBracket = fileInfo.find('(');
                string fileName = fileInfo.substr(0, openBracket);
                string content = fileInfo.substr(openBracket + 1, fileInfo.size() - openBracket - 2);
                string fullPath = directory + "/" + fileName;
                
                contentToFiles[content].push_back(fullPath);
            }
        }
        
        vector<vector<string>> result;
        for (auto& entry : contentToFiles) {
            if (entry.second.size() > 1) {
                result.push_back(entry.second);
            }
        }
        
        return result;
    }
};
```

```python
class Solution:
    def findDuplicate(self, paths: List[str]) -> List[List[str]]:
        content_to_files = {}
        
        for path in paths:
            parts = path.split(" ")
            directory = parts[0]
            
            for fileInfo in parts[1:]:
                file_parts = fileInfo.split("(")
                file_name = file_parts[0]
                content = file_parts[1][:-1]
                full_path = directory + "/" + file_name
                
                if content not in content_to_files:
                    content_to_files[content] = []
                content_to_files[content].append(full_path)
        
        result = [files for files in content_to_files.values() if len(files) > 1]
        
        return result
```